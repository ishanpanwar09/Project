a = 1.75
a*2*3*4
4*2*3*4
RogueAd <- 0.10
?pnorm()
N9 <- 2.576
N5 <- 1.96
N0 <- 1.645
ErrM <- 0.01
pHat <- 0.01
pHat <- 0.1
q <- 1-pHat
gHat <- 1- pHat
qHat <- 1- pHat
rm(gHat)
Mul <- pHat * qHat
ZscoreNorm <- N0/ErrM
ZscoreNormSquared <- ZscoreNorm**2
SampleSize <- ZscoreNormSquared * Mul
SampleSize
library(h20)
library(h2o)
h2o.init(nthreads = -1,max_mem_size = "10G")
library(h2o)
h2o.init(nthreads = -1,max_mem_size = "10G")
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
pkgs <- c("methods","statmod","stats","graphics","RCurl","jsonlite","tools","utils")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
install.packages("h2o", type="source", repos=(c("http://h2o-release.s3.amazonaws.com/h2o/rel-turchin/8/R")))
library(h2o)
install.packages("statmod")
install.packages("statmod")
library(h2o)
h2o.init(nthreads=-1)
h2o.init(nthreads=-1)
b1 <- 0.2
b2 <- 0.2
pui <- 0.5
si <- specify_decimal(pui*((1-b1)*b2+b1*(1-b2)),5)
print(si)
signif(si,6)
b1 <- 0.2
b2 <- 0.2
pui <- 0.5
si <- pui*((1-b1)*b2+b1*(1-b2))
print(si)
print(signif(si,6))
print(signif(si,6))
formattable(si, digits = 6, format = "f")
si
signif(si, digits = 6)
options(digits=10)
signif(si, digits = 6)
?option
sprintf("%.100f",si)
sprintf("%.1f",si)
sprintf("%.10f",si)
signif(sprintf("%.10f",si)),6)
signif(s,5)
s<-sprintf("%.10f",si)
signif(s,5)
round(sprintf("%.10f",si),6)
round(sprintf("%.10f",si),digit = 6)
format(round(1.20, 2), nsmall = 2)
format(round(1.20, 3), nsmall = 2)
format(round(1.20, 3), nsmall = 3)
format(round(1.20, 3), nsmall = 4)
format(si, nsmall = 6)
as.integer(format(si, nsmall = 6))
as.numeric(format(si, nsmall = 6))
as.numeric_version(format(si, nsmall = 6))
as.numeric(format(si, nsmall = 6))
install.packages("stringr")
library(stringr)
str_pad(si, width=6, side="left", pad="0")
str_pad(si, width=2, side="left", pad="0")
str_pad(si, width=10, side="left", pad="0")
str_pad(si, width=6, side="right", pad="0")
str_pad(si, width=8, side="right", pad="0")
runif(10)
runif(10, 2,100)
data("AirPassengers")
show(AirPassengers)
split_data <- runif(nrow(AirPassengers))
rm(AirPassengers)
data("iris")
split_data <- runif(nrow(iris))
train <- iris[split_data > 0.6]
train <- iris[split_data > 0.6,]
train <- iris[split_data > 0.3,]
test <- iris[split_data < 0.4,]
train <- iris[split_data >= 0.3,]
train <- iris[split_data < 0.3,]
train <- iris[split_data >= 0.3,]
test <- iris[split_data < 0.3,]
iris
outcome_name = 'Species'
feature_names = setdiff(names(iris),outcome_name)
set.seed(1)
library(randomForest)
rf_model = randomForest(train[,feature_names], y = as.factor(train[,outcome_name]),importance = T, ntree = 30, mtry = 3)
rf_model
pred = predict(rf_model, test[,feature_names], type = "probability")
pred = predict(rf_model, test[,feature_names], type = "prob")
pred
pred = predict(rf_model, test[,feature_names], type = "votes")
pred = predict(rf_model, test[,feature_names], type = "vote")
pred
data(iris)
split_data = runif(nrow(iris))
train = iris[split_data >= 0.25,]
test = iris[split_data <0.25,]
cl = "Species"
features = setdiff(iris, iris[,cl])
features = setdiff(names(iris), iris[,cl])
library(randomForest)
rf_model = randomForest(x = train[,features], y = as.factor(cl), importance = T, ntree = 35, mtry = 10)
rf_model = randomForest(x = train[,features], y = as.factor(train[,cl]), importance = T, ntree = 35, mtry = 10)
rf_model = randomForest(x = train[,features], y = as.factor(train[,cl]), importance = T, ntree = 35, mtry = 8)
rf_model = randomForest(x = train[,features], y = as.factor(train[,cl]), importance = T, ntree = 35, mtry = 7)
rf_model = randomForest(x = train[,features], y = as.factor(train[,cl]), importance = T, ntree = 35, mtry = 6)
rf_model = randomForest(x = train[,features], y = as.factor(train[,cl]), importance = T, ntree = 35, mtry = 5)
pred = predict(rf_model, test[,features], type = "prob")
head(pred)
pred
varImpPlot(train)
varImpPlot(rf_model)
rf_model$importance
install.package("ROC")
install.packages("ROC")
install.packages("ROC", dependencies = T)
library(h2o)
loclH2o = h2o.init()
iris_h2o = as.h2o
iris_h2o = as.h2o(train)
rm(iris_h2o)
iris_train = as.h2o(train)
iris_test = as.h2o(test)
dlm = h2o.deeplearning(features,iris_train,
autoencoder = T,
seed = 123,
hidden = c(6,5,7),
epochs = 50)
iris_train = as.h2o(train, destination_frame = 'train.hex')
dlm = h2o.deeplearning(features,iris_train,
autoencoder = T,
seed = 123,
hidden = c(6,5,7),
epochs = 50)
dlm = h2o.deeplearning(features,iris_train,
autoencoder = T,
reproducible = T,
seed = 123,
hidden = c(6,5,7),
epochs = 50)
iris_train
dlm = h2o.deeplearning(features,iris_train,
autoencoder = T,
reproducible = T,
seed = 123,
hidden = c(7,6,7),
epochs = 50)
iris_train = as.h2o(train, destination_frame = 'train_df.hex')
dlm = h2o.deeplearning(features,iris_train,
autoencoder = T,
reproducible = T,
seed = 123,
hidden = c(7,6,7),
epochs = 50)
?as.h2o
typeof(iris_train)
typeof(train)
as.data.frame(train)
iris_train= as.h2o(as.data.frame(train))
typeof(iris_train)
dlm = h2o.deeplearning(features,iris_train,
autoencoder = T,
reproducible = T,
seed = 123,
hidden = c(7,6,7),
epochs = 50)
dlm = h2o.deeplearning(features,iris_train,
autoencoder = T,
reproducible = T,
seed = 123,
hidden = c(7,6,7),
epochs = 50)
library(randomForest)
library(h2o)
data(iris)
split_data = runif(nrow(iris))
test = iris[split_data < 0.25,]
train = iris[split_data >= 0.25,]
View(iris)
Result = 'Species'
features = setdiff(names(iris, Result))
features = setdiff(names(iris(), Result)
features = setdiff(names(iris), Result)
features = setdiff(names(iris), iris[,Result])
features
features = setdiff(names(iris), iris[,Result])
ncol(iris)
features = setdiff(names(iris), iris[,Result])
features = setdiff(names(iris), iris[,Result])
load(iris)
load(iris)
iris
write.csv(abc,iris)
abc = as.data.frame(iris)
write.csv(abc,iris)
?write.csv()
write.csv(abc,"tr.csv")
library(caret)
?knn3()
df = iris
sp = runif(length(df))
train = df[sp>0.7,]
train = df[sp>0.2,]
test = df[sp<=.2]
test = df[sp<0.2]
train = df[sp>=0.2,]
test = df[sp<0.2,]
cl = as.factor(df[,5])
cl = levels(factor(df[,5]))
kn = knn3(Species~.,train)
test[,-5]
predict(kn,test[,-5]), type = 'class')
test = test[,-5]
test = df[sp<0.2,]
testCl = test[,-5]
predict(kn,test, type = 'class')
predict(kn,test, type = c('class','prob')
)
predict(kn,test, type = c('class','prob'))
predict(kn,test, type = 'prob')
predict(kn,test, type = 'pr')
predict(kn,test, type = 'p')
predict(kn,test, type = 'c')
predict(kn,test, type = 't')
sig<- function(x){}
sig <- function(x){
output = 1/(1+exp(-x))
return(output)
}
sig(2)
sig(4)
exp(-2)
exp(-2)+1
exp(2)
exp(-2)+1
1/exp(-2)+1
1/(exp(-2)+1)
sig(4)
sig(4)*(1-sig(4))
setwd("~/Documents/tf_ishan/april_26_5PM")
df = read.csv('Concert_metadata.csv')
View(df)
df[,-1]
df = df[,-1]
df[, 1:2]
df[, 2:3]
df[, 1:2]
set.seed(20)
irisCluster <- kmeans(df[, 1:2], 3, nstart = 20)
irisCluster <- kmeans(df[, 1:2], 2, nstart = 20)
irisCluster <- kmeans(df[, 1:2], 1, nstart = 20)
df2 = data("iris")
df2[,3:4]
irisCluster <- kmeans(df2[, 3:4], 3, nstart = 20)
head("iris")
head(iris)
aer <- kmeans(iris[, 3:4], 3, nstart = 20)
aer
?kmeans
View(iris)
iris[, 3:4]
irisCluster
aer
plot(aer)
plot(aer$cluster)
plot(aer$cluster, type = 'l')
plot(aer$cluster)
irisCluster <- kmeans(df[, 1], 3, nstart = 20)
irisCluster <- kmeans(df[, 1], 3, nstart = 2)
irisCluster <- kmeans(df[, 1], 3, nstart = 0.4)
irisCluster
df[, 1]
irisCluster <- kmeans(df[, 2], 3, nstart = 0.4)
irisCluster
irisCluster <- kmeans(df[, 2], 3, nstart = 2)
irisCluster
plot(irisCluster$cluster)
irisCluster <- kmeans(df[, 2], 5, nstart = 2)
plot(irisCluster$cluster)
irisCluster <- kmeans(df[, 2], 10
, nstart = 2)
plot(irisCluster$cluster)
aer
concert = read.csv('/Users/ishansingh/Documents/tf_ishan/april_26_5PM/metadata_extracted/Concert_metadata.csv')
conference = read.csv('/Users/ishansingh/Documents/tf_ishan/april_26_5PM/metadata_extracted/Conference_metadata.csv')
cycling = read.csv('/Users/ishansingh/Documents/tf_ishan/april_26_5PM/metadata_extracted/Cycling_metadata.csv')
football = read.csv('/Users/ishansingh/Documents/tf_ishan/april_26_5PM/metadata_extracted/Football_metadata.csv')
library(dplyr)
gpConcert= group_by(concert,name)
concert= summarise(gpConcert,count = n())
concert$class = rep('concert',length(concert$name))
gpCycling= group_by(cycling,name)
cycling= summarise(gpCycling,count = n())
cycling$class = rep('Cycling',length(cycling$name))
gpConference = group_by(conference,name)
conference= summarise(gpConference,count = n())
conference$class = rep('conference',length(conference$name))
gpfootball= group_by(football,name)
football= summarise(gpfootball,count = n())
football$class = rep('football',length(football$name))
NewDF = rbind(cycling,concert,conference, football)
write.csv(NewDF, 'All_metadata.csv')
NewDF = NewDF%>%
filter(count > 90)
library(ggplot2)
q= ggplot(data=NewDF, aes(x=name, y=count, fill=class)) + geom_bar(stat="identity") +
ggtitle(expression("Stacked bar chart of prominent concepts (metaData) of all classes"))
q = q + theme(legend.position="top")
q = q + theme(legend.background = element_rect(fill="lightblue",
size=0.5, linetype="solid"))
q + theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 6))
q = ggplot(NewDF, aes(x=name, y=count, color = class)) + geom_point()
q + theme(axis.text.x = element_text(angle = 90, hjust = 1))
q = ggplot(NewDF, aes(x=factor(class), y=count, fill=name)) +
geom_bar(aes(fill = name), position = "dodge", stat="identity") +
labs(x = "Prominent Concepts") +
labs(y = expression("blank")) +
xlab("bla") +
ggtitle(expression("Histogram of Prominent Concepts (MetaData)"))
q + theme(axis.text.x = element_text(angle = 90, hjust = 1))
